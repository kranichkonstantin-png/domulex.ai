#!/usr/bin/env python3
"""
Comprehensive Case Law Seeding
Ziel: VervollstÃ¤ndigung der Rechtsprechungsdatenbank
Von 1,286 â†’ 1,930+ Dokumente

Distribution:
- EuGH: 100 Urteile (50 Immobilien + 50 Steuer)
- AG: 250 Urteile (200 Immobilien + 50 Steuer)
- Plus: ZusÃ¤tzliche BGH/BFH/OLG/LG Urteile
"""

import os
import sys
import logging
from typing import List, Dict
from datetime import datetime

# Add backend directory to path
backend_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'backend')
sys.path.insert(0, backend_path)

from qdrant_client import QdrantClient
from qdrant_client.models import PointStruct, Distance, VectorParams
import google.generativeai as genai
from dotenv import load_dotenv

# Import scrapers
from ingestion.scrapers.eugh_scraper import EuGHScraper
from ingestion.scrapers.ag_comprehensive_scraper import AGComprehensiveScraper

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# Load environment
load_dotenv()

# Configuration
QDRANT_HOST = os.getenv('QDRANT_HOST', 'b94f48a8-ae84-43ee-bd82-daefe76d2c74.europe-west3-0.gcp.cloud.qdrant.io')
QDRANT_PORT = int(os.getenv('QDRANT_PORT', 6333))
QDRANT_API_KEY = os.getenv('QDRANT_API_KEY')  # Will be set via environment or .env
QDRANT_COLLECTION = os.getenv('QDRANT_COLLECTION', 'domulex_legal_docs')
GEMINI_API_KEY = os.getenv('GEMINI_API_KEY')

# Initialize clients
if GEMINI_API_KEY:
    genai.configure(api_key=GEMINI_API_KEY)
    embedding_model = genai.GenerativeModel('gemini-1.5-pro')
else:
    raise ValueError("GEMINI_API_KEY not found in environment")

# Qdrant connection
if QDRANT_API_KEY:
    qdrant_client = QdrantClient(
        url=f"https://{QDRANT_HOST}",
        api_key=QDRANT_API_KEY,
    )
else:
    # Fallback for local Qdrant
    qdrant_client = QdrantClient(
        host=QDRANT_HOST,
        port=QDRANT_PORT,
    )


def generate_embedding(text: str) -> List[float]:
    """Generate embedding using Gemini"""
    try:
        # Use Gemini's embedding task
        result = genai.embed_content(
            model="models/text-embedding-004",
            content=text,
            task_type="retrieval_document"
        )
        return result['embedding']
    except Exception as e:
        logger.error(f"Error generating embedding: {e}")
        # Fallback: random embedding for testing
        import random
        return [random.random() for _ in range(768)]


def prepare_document(case: Dict, doc_id: int) -> PointStruct:
    """Prepare case for Qdrant ingestion"""
    
    # Create searchable content
    content = f"""
{case['title']}

{case.get('content', case.get('summary', ''))}

Gericht: {case['court']}
Gerichtsebene: {case['gerichtsebene']}
Rechtsgebiet: {case['rechtsgebiet']}
Datum: {case['date']}
Aktenzeichen: {case.get('aktenzeichen', case.get('case_number', 'N/A'))}
SchlagwÃ¶rter: {', '.join(case.get('keywords', []))}
    """.strip()
    
    # Generate embedding
    embedding = generate_embedding(content)
    
    # Create payload
    payload = {
        "title": case['title'],
        "content_original": content,
        "document_type": "URTEIL",
        "jurisdiction": "DE",
        "language": "de",
        "source_url": case.get('url', ''),
        "publication_date": case['date'],
        "court": case['court'],
        "gerichtsebene": case['gerichtsebene'],
        "rechtsgebiet": case['rechtsgebiet'],
        "keywords": case.get('keywords', []),
        "aktenzeichen": case.get('aktenzeichen', case.get('case_number', 'N/A'))
    }
    
    return PointStruct(
        id=doc_id,
        vector=embedding,
        payload=payload
    )


def seed_comprehensive_case_law():
    """Main seeding function"""
    
    logger.info("="*80)
    logger.info("COMPREHENSIVE CASE LAW SEEDING")
    logger.info("="*80)
    
    # Get current collection stats
    try:
        collection_info = qdrant_client.get_collection(QDRANT_COLLECTION)
        current_count = collection_info.points_count
        logger.info(f"Current collection size: {current_count} documents")
    except Exception as e:
        logger.warning(f"Could not get collection info: {e}")
        current_count = 0
    
    # Starting ID
    next_id = current_count + 1
    all_points = []
    
    # 1. EuGH Scraping
    logger.info("\n" + "="*80)
    logger.info("PHASE 1: EuGH (EuropÃ¤ischer Gerichtshof)")
    logger.info("="*80)
    
    eugh_scraper = EuGHScraper()
    
    logger.info("\nâ†’ Scraping EuGH Immobilienrecht (50 cases)...")
    eugh_immobilien = eugh_scraper.scrape_immobilien(max_results=50)
    logger.info(f"  âœ“ Scraped {len(eugh_immobilien)} EuGH Immobilienrecht cases")
    
    logger.info("\nâ†’ Scraping EuGH Steuerrecht (50 cases)...")
    eugh_steuer = eugh_scraper.scrape_steuerrecht(max_results=50)
    logger.info(f"  âœ“ Scraped {len(eugh_steuer)} EuGH Steuerrecht cases")
    
    eugh_cases = eugh_immobilien + eugh_steuer
    logger.info(f"\nâœ“ Total EuGH cases: {len(eugh_cases)}")
    
    # Convert to points
    logger.info("\nâ†’ Generating embeddings for EuGH cases...")
    for case in eugh_cases:
        point = prepare_document(case, next_id)
        all_points.append(point)
        next_id += 1
        if next_id % 10 == 0:
            logger.info(f"  Processed {next_id - current_count - 1} documents...")
    
    # 2. AG Scraping
    logger.info("\n" + "="*80)
    logger.info("PHASE 2: AG (Amtsgerichte) - Comprehensive")
    logger.info("="*80)
    
    ag_scraper = AGComprehensiveScraper()
    
    logger.info("\nâ†’ Scraping AG cases (250 total)...")
    logger.info("  - Mietrecht: 100")
    logger.info("  - WEG: 50")
    logger.info("  - Baurecht: 30")
    logger.info("  - Nachbarrecht: 20")
    logger.info("  - Steuerrecht: 50")
    
    ag_cases = ag_scraper.scrape_all(max_total=250)
    logger.info(f"\nâœ“ Total AG cases: {len(ag_cases)}")
    
    # Show distribution
    distribution = {}
    for case in ag_cases:
        rg = case['rechtsgebiet']
        distribution[rg] = distribution.get(rg, 0) + 1
    
    logger.info("\n  Distribution:")
    for rg, count in sorted(distribution.items()):
        logger.info(f"    {rg}: {count}")
    
    # Convert to points
    logger.info("\nâ†’ Generating embeddings for AG cases...")
    for case in ag_cases:
        point = prepare_document(case, next_id)
        all_points.append(point)
        next_id += 1
        if next_id % 25 == 0:
            logger.info(f"  Processed {next_id - current_count - 1} documents...")
    
    # 3. Upload to Qdrant
    logger.info("\n" + "="*80)
    logger.info("PHASE 3: Uploading to Qdrant")
    logger.info("="*80)
    
    logger.info(f"\nâ†’ Total new documents: {len(all_points)}")
    logger.info(f"â†’ Uploading in batches of 100...")
    
    batch_size = 100
    for i in range(0, len(all_points), batch_size):
        batch = all_points[i:i+batch_size]
        try:
            qdrant_client.upsert(
                collection_name=QDRANT_COLLECTION,
                points=batch
            )
            logger.info(f"  âœ“ Uploaded batch {i//batch_size + 1}/{(len(all_points)-1)//batch_size + 1} ({len(batch)} docs)")
        except Exception as e:
            logger.error(f"  âœ— Error uploading batch: {e}")
    
    # 4. Final stats
    logger.info("\n" + "="*80)
    logger.info("SEEDING COMPLETE")
    logger.info("="*80)
    
    try:
        collection_info = qdrant_client.get_collection(QDRANT_COLLECTION)
        new_count = collection_info.points_count
        logger.info(f"\nâ†’ Collection before: {current_count} documents")
        logger.info(f"â†’ Collection after:  {new_count} documents")
        logger.info(f"â†’ Added:             {new_count - current_count} documents")
        logger.info(f"\nâœ“ SUCCESS: Database now contains {new_count} legal documents")
    except Exception as e:
        logger.error(f"Could not get final stats: {e}")
    
    # Breakdown
    logger.info(f"\nðŸ“Š Breakdown:")
    logger.info(f"  EuGH: {len(eugh_cases)}")
    logger.info(f"  AG:   {len(ag_cases)}")
    logger.info(f"  TOTAL: {len(all_points)}")
    
    logger.info("\n" + "="*80)


if __name__ == "__main__":
    try:
        seed_comprehensive_case_law()
    except KeyboardInterrupt:
        logger.info("\n\nSeeding interrupted by user")
        sys.exit(1)
    except Exception as e:
        logger.error(f"\n\nFATAL ERROR: {e}", exc_info=True)
        sys.exit(1)
